{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfS9klMysiJe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler   # u otros scalers\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from distancia import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Etu10JAIsiJk"
   },
   "outputs": [],
   "source": [
    "### carga datos de dataset en dataframe\n",
    "file_path= 'uber_fares.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4wFXcfZsiJm",
    "outputId": "26d5e365-cdcd-48ff-df86-65ef8a784b32"
   },
   "outputs": [],
   "source": [
    "### visualizacion de algunos datos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xd_uOYe1siJn"
   },
   "source": [
    "#### Contexto  \n",
    "El proyecto trata sobre **Uber Inc.**, la compañía de taxis más grande del mundo. En este trabajo, nuestro objetivo es **predecir la tarifa de futuros viajes**.  \n",
    "\n",
    "Uber brinda servicio a millones de clientes cada día, por lo que gestionar adecuadamente sus datos es clave para desarrollar nuevas estrategias de negocio y obtener mejores resultados.  \n",
    "\n",
    "### Variables del conjunto de datos  \n",
    "\n",
    "**Variables explicativas:**  \n",
    "- **key**: identificador único de cada viaje.  \n",
    "- **pickup_datetime**: fecha y hora en que se inició el viaje.  \n",
    "- **passenger_count**: cantidad de pasajeros en el vehículo (dato ingresado por el conductor).  \n",
    "- **pickup_longitude**: longitud del punto de inicio del viaje.  \n",
    "- **pickup_latitude**: latitud del punto de inicio del viaje.  \n",
    "- **dropoff_longitude**: longitud del punto de destino.  \n",
    "- **dropoff_latitude**: latitud del punto de destino.  \n",
    "\n",
    "**Variable objetivo (target):**  \n",
    "- **fare_amount**: costo del viaje en dólares.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tf2N8kt_siJp",
    "outputId": "8b0f80b4-5783-4e13-cc89-aa7416b0f0f3"
   },
   "outputs": [],
   "source": [
    "### Columnas, ¿cuáles son variables numéricas y cuales variables categóricas?\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este dataset trabajaremos con algunas columnas de interes, las cuales clasificamos a continuacion dependiendo el tipo de variable:\n",
    "\n",
    "*   **fare_amount:**   cuantitativa continua\n",
    "*   **pickup_datetime:** cualitativa nominal\n",
    "*   **pickup_longitude:** cuantitativa continua\n",
    "*   **pickup_latitude:** cuantitativa continua\n",
    "*   **dropoff_longitude:** cuantitativa continua\n",
    "*   **dropoff_latitude:** cuantitativa continua\n",
    "*   **passenger_count:** cuantitativa discreta\n",
    "\n",
    "Lo primero que realizaremos será utilizar el método `.info()` para verificar que el tipo de dato en cada variable es correcto, detectar la presencia de valores nulos y valores atípicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='fare_amount'), df['fare_amount'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4G7p47V_siJq",
    "outputId": "a7eb128e-f4ae-4332-c92d-162cc8733da7"
   },
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar la fila con valores nulos\n",
    "X_train[X_train.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de los datos\n",
    "Podemos observar a traves del 'X_train.info' que tenemos 200.000 datos donde las columnas 'dropoff_longitude' y 'dropoff_latitude' poseen un valor faltante en sus datos. Consideramos que al tener una muestra de datos abundante, decidimos eliminarlos del dataset ya que no afecta al entrenamiento del modelo y evitar imputar los datos con un valor promedio. Además, modificamos el tipo de dato de 'pickup_datetime' para verificar que todas las fechas ingresadas hayan sido correctamente cargadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambia el tipo de dato object -> datetime\n",
    "X_train['pickup_datetime'] = pd.to_datetime(X_train['pickup_datetime'])                   \n",
    "# Elimina las filas con valores nulos\n",
    "#X_train.dropna(inplace=True)     #No haria falta lo hacemos con imputacion\n",
    "\n",
    "# Eliminación de columnas que no son de interes\n",
    "X_train = X_train.drop('key', axis = 1)\n",
    "X_train = X_train.drop('date', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de esto, realizamos un '.describe()' sobre las variables numericas y consideramos los resultados para analizar cada variable del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Análisis de la columna `passenger_count`:**\n",
    "\n",
    "A partir del análisis exploratorio mediante `.describe()`, se detectó que el valor máximo registrado en la variable fue de 208 pasajeros por viaje, lo cual constituye un error en la carga de datos. Para visualizar la distribución se realizaron diferentes gráficos:  \n",
    "\n",
    "- En el **primer boxplot**, se observa claramente el valor atípico de 208, lo que impide una correcta interpretación del resto de los datos.  \n",
    "- Al excluir dicho valor extremo, el **segundo boxplot** permite observar mejor la dispersión real de la variable.  \n",
    "\n",
    "Además, se identificaron registros con 0 pasajeros, los cuales también son inconsistentes, ya que un viaje no puede realizarse sin pasajeros.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">quizas deberiamos calcular los valores atipicos con q1 y q3 como en distancia??</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x = X_train['passenger_count'])\n",
    "plt.title('Boxplot de cantidad de pasajeros sin filtrar')\n",
    "plt.xlabel('Cantidad de pasajeros')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x = X_train[X_train['passenger_count'] < 208]['passenger_count'])\n",
    "plt.title('Boxplot de cantidad de pasajero filtrado')\n",
    "plt.xlabel('Cantidad de pasajeros')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_train[X_train['passenger_count'] < 208]['passenger_count'], color = 'green')\n",
    "plt.title('Histograma de cantidad de pasajeros menor a 208')\n",
    "plt.xlabel('Cantidad de pasajeros')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para solucionar este problema y no eliminar dichos registros, se decidió imputar el valor atípico de 208 y tratar los datos con 0 pasajeros con la **mediana de la distribución**. La mediana es la medida de tendencia central y es robusta frente a valores atípicos y representa de forma adecuada la cantidad más común de pasajeros en los viajes (generalmente 1). Finalmente, la columna fue convertida a valores enteros para mantener consistencia en la variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X_train.loc[X_train['passenger_count'] == 208, 'passenger_count'] = pd.NA\n",
    "X_train.loc[X_train['passenger_count'] == 0, 'passenger_count'] = pd.NA\n",
    "imputer = SimpleImputer(strategy='median')                                      # Imputar con la mediana\n",
    "X_train['passenger_count'] = imputer.fit_transform(X_train[['passenger_count']])\n",
    "X_train['passenger_count'] = X_train['passenger_count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_train['passenger_count'], color = 'green')\n",
    "plt.title('Histograma de cantidad de pasajeros transformado')\n",
    "plt.xlabel('Cantidad de pasajeros')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análisis de las columnas `pickup_latitude`, `dropoff_latitude`, `pickup_longitude` y `dropoff_longitude`\n",
    "\n",
    "Para analizar estos datos, lo primero que realizamos fue la visualización gráfica de cada variable. En estas gráficas se observan bastantes valores atípicos que no corresponden a rangos válidos de latitud y longitud:  \n",
    "\n",
    "- **Rangos globales válidos**:  \n",
    "  - Latitud: -90 a 90  \n",
    "  - Longitud: -180 a 180  \n",
    "\n",
    "Vamos a considerar las coordenadas que caigan dentro de estos rangos o bien tengan una sola coordenada de las 4 posibles fuera del rango.\n",
    "En estos casos imputariamos la coordenada invalida con KNN\n",
    "\n",
    "<span style=\"color: red;\">Esto no lo pondria, porque esto seria una suposicion nuestra</span>\n",
    "- **Rangos aproximados para New York**:  \n",
    "  - Latitud: 40.50 a 41.00  \n",
    "  - Longitud: -74.20 a -73.60  \n",
    "\n",
    "De esta manera, se eliminan registros con coordenadas fuera de este rango, ya que son considerados como datos no representativos de la zona de análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,5))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"Datos de 'pickup_longitude'\")\n",
    "sns.boxplot(X_train['pickup_longitude'])\n",
    "plt.ylabel('Longitud de inicio')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"Datos de 'dropoff_longitude'\")\n",
    "sns.boxplot(X_train['dropoff_longitude'])\n",
    "plt.ylabel('Longitud final')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"Datos de 'pickup_latitude'\")\n",
    "sns.boxplot(X_train['pickup_latitude'])\n",
    "plt.ylabel('Latitud de inicio')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"Datos de 'dropoff_latitude'\")\n",
    "sns.boxplot(X_train['dropoff_latitude'])\n",
    "plt.ylabel('Latitud final')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto creo que lo podemos quitar\n",
    "\n",
    "# longitud = df[(df['pickup_longitude'] == 0.00) & (df['dropoff_longitude'] == 0.00)].value_counts().sum()  # 3587 datos\n",
    "# latitud = df[(df['pickup_longitude'] == 0.00) & (df['dropoff_longitude'] == 0.00)].value_counts().sum()   # 3587 datos\n",
    "# lat_long = df[(df['pickup_latitude'] == 0.00) & (df['dropoff_latitude'] == 0.00) & (df['pickup_longitude'] == 0.00) & (df['dropoff_longitude'] == 0.00)].value_counts().sum()\n",
    "# print(f'datos nulos en latitud y longitud: {lat_long}') # 3587 datos\n",
    "# print(f'datos nulos en longitud: {longitud}')\n",
    "# print(f'datos nulos en latitud: {latitud}\\n')\n",
    "\n",
    "# longitud1 = df[df['dropoff_longitude'] == 0.00].value_counts().sum()  # 177 datos\n",
    "# longitud2 = df[df['pickup_longitude'] == 0.00].value_counts().sum()   # 199 datos \n",
    "# latitud1 = df[(df['pickup_latitude'] == 0.00)].value_counts().sum()   # 177 datos \n",
    "# latitud2 = df[(df['dropoff_latitude'] == 0.00)].value_counts().sum()  # 171 datos \n",
    "# print(f'datos nulos en longitud inicio: {longitud2}')\n",
    "# print(f'datos nulos en longitud final: {longitud1}')\n",
    "# print(f'datos nulos en latitud inicio: {latitud1}')\n",
    "# print(f'datos nulos en latitud final: {latitud2}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que existen registros en los cuales tanto la latitud como la longitud (de inicio y de destino) tienen valor igual a 0. Estos registros no aportan información relevante al análisis, ya que corresponden a errores de carga, por lo que se decidió **eliminarlos del dataset** para trabajar únicamente con datos reales.  \n",
    "\n",
    "Por otro lado, aquellos registros en los que solo **una de las coordenadas** (latitud o longitud, ya sea en inicio o destino) tiene valor igual a 0, pueden ser imputados por aproximación. En este caso, en lugar de eliminarlos, se optó por reemplazar dichos valores utilizando el método de imputación por K-vecinos más cercanos (KNN), lo cual permite estimar las coordenadas faltantes en base a los viajes más similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[(X_train['pickup_latitude'] == 0.00) &(X_train['dropoff_latitude'] == 0.00) &(X_train['pickup_longitude'] == 0.00) &(X_train['dropoff_longitude'] == 0.00)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con todas las coordenadas en 0\n",
    "#indices_invalidos = X_train[(X_train['pickup_latitude'] == 0.00) &(X_train['dropoff_latitude'] == 0.00) &(X_train['pickup_longitude'] == 0.00) &(X_train['dropoff_longitude'] == 0.00)].index\n",
    "#X_train = X_train.drop(indices_invalidos)\n",
    "# Cantidad de filas eliminadas\n",
    "#print(f'Cantidad de filas eliminadas: {len(indices_invalidos)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recorrer el dataset X_train y chequear si las coordenadas son validas o cero o nan y si no los son reemplazarlas con NaN\n",
    "# si una fila tiene mas de 1 coordenada invalida, eliminar la fila\n",
    "# mostrar la cantidad de filas eliminadas\n",
    "# mostrar la cantidad de filas modificadas a NaN\n",
    "\n",
    "modified_count = 0\n",
    "initial_rows = X_train.shape[0] # cantidad inicial de filas\n",
    "for index, row in X_train.iterrows():\n",
    "    invalid_count = 0\n",
    "\n",
    "    if not (-90 <= row['pickup_latitude'] <= 90) or row['pickup_latitude'] == 0.0 or pd.isna(row['pickup_latitude']): \n",
    "        X_train.at[index, 'pickup_latitude'] = pd.NA\n",
    "        invalid_count += 1\n",
    "    if not (-90 <= row['dropoff_latitude'] <= 90 or row['dropoff_latitude'] == 0.0) or pd.isna(row['dropoff_latitude']):\n",
    "        X_train.at[index, 'dropoff_latitude'] = pd.NA\n",
    "        invalid_count += 1\n",
    "    if not (-180 <= row['pickup_longitude'] <= 180) or row['pickup_longitude'] == 0.0 or pd.isna(row['pickup_longitude']):\n",
    "        X_train.at[index, 'pickup_longitude'] = pd.NA\n",
    "        invalid_count += 1\n",
    "    if not (-180 <= row['dropoff_longitude'] <= 180) or row['dropoff_longitude'] == 0.0 or pd.isna(row['dropoff_longitude']):\n",
    "        X_train.at[index, 'dropoff_longitude'] = pd.NA\n",
    "        invalid_count += 1\n",
    "    if invalid_count > 1:\n",
    "        X_train = X_train.drop(index)\n",
    "        y_train = y_train.drop(index)\n",
    "    elif invalid_count == 1:\n",
    "        modified_count += 1\n",
    "\n",
    "print(f'Cantidad de filas modificadas a NaN: {modified_count}')\n",
    "final_rows = X_train.shape[0] # cantidad final de filas\n",
    "print(f'Cantidad de filas eliminadas: {initial_rows - final_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "columnas = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
    "#k muy pequeño → más sensible a ruido. k muy grande → valores muy suavizados, se pierde variabilidad real.\n",
    "\n",
    "# Crear imputador KNN\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "X_train[columnas] = knn_imputer.fit_transform(X_train[columnas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,5))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"Datos de 'pickup_longitude'\")\n",
    "sns.boxplot(X_train['pickup_longitude'], color=\"skyblue\")\n",
    "plt.ylabel('Longitud de inicio')\n",
    "\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"Datos de 'dropoff_longitude'\")\n",
    "sns.boxplot(X_train['dropoff_longitude'], color=\"pink\")\n",
    "plt.ylabel('Longitud final')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"Datos de 'pickup_latitude'\")\n",
    "sns.boxplot(X_train['pickup_latitude'], color=\"skyblue\")\n",
    "plt.ylabel('Latitud de inicio')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"Datos de 'dropoff_latitude'\")\n",
    "sns.boxplot(X_train['dropoff_latitude'], color=\"pink\")\n",
    "plt.ylabel('Latitud final')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar mas caraterísticas a partir de las coordenadas geográficas\n",
    "X_train[\"delta_lat\"] = X_train[\"dropoff_latitude\"] - X_train[\"pickup_latitude\"]\n",
    "X_train[\"delta_lon\"] = X_train[\"dropoff_longitude\"] - X_train[\"pickup_longitude\"]\n",
    "\n",
    "X_train[\"distance_km\"] = X_train.apply(\n",
    "    lambda row: haversine(\n",
    "        row[\"pickup_longitude\"], row[\"pickup_latitude\"],\n",
    "        row[\"dropoff_longitude\"], row[\"dropoff_latitude\"]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hW-QZN1ysiJr",
    "outputId": "34124413-5a9d-4a42-f173-2e7cf5879880"
   },
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograma de la distancia en km\n",
    "\n",
    "plt.hist(X_train['distance_km'], bins=50, color='blue', alpha=0.7)\n",
    "plt.title('Histograma de la distancia en km')\n",
    "plt.xlabel('Distancia (km)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograma del logaritmo de la distancia en km\n",
    "plt.hist(np.log1p(X_train['distance_km']), bins=50, color='blue', alpha=0.7)\n",
    "plt.title('Histograma del logaritmo de la distancia en km')\n",
    "plt.xlabel('Log(Distancia + 1)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular el primer cuartil (Q1) y el tercer cuartil (Q3)\n",
    "Q1 = X_train['distance_km'].quantile(0.25)\n",
    "Q3 = X_train['distance_km'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "# definir los límites para los valores atípicos\n",
    "lower_bound = Q1 - 5 * IQR\n",
    "upper_bound = Q3 + 5 * IQR\n",
    "print(f'Q1: {Q1}, Q3: {Q3}, IQR: {IQR}, Lower Bound: {lower_bound}, Upper Bound: {upper_bound}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular la cantidad de valores atípicos\n",
    "outliers = X_train[(X_train['distance_km'] < lower_bound) | (X_train['distance_km'] > upper_bound)]\n",
    "print(f'Cantidad de valores atípicos: {outliers.shape[0]}')\n",
    "print(f'Porcentaje de valores atípicos: {outliers.shape[0] / X_train.shape[0] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener index de los datos para eliminar los valores atípicos\n",
    "outlier_indices = outliers.index\n",
    "# eliminar los datos atípicos de x_train y y_train\n",
    "y_train = y_train.drop(outlier_indices)\n",
    "X_train = X_train.drop(outlier_indices)\n",
    "\n",
    "\n",
    "plt.hist(X_train['distance_km'], bins=50, color='blue', alpha=0.7)\n",
    "plt.title('Histograma de la distancia en km')\n",
    "plt.xlabel('Distancia (km)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPyrf0vbsiJs"
   },
   "outputs": [],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograma de y_train\n",
    "plt.hist(y_train, bins=50, color='orange', alpha=0.7)\n",
    "plt.title('Histograma de y_train (fare_amount)')\n",
    "plt.xlabel('Fare Amount')\n",
    "plt.ylabel('Frecuencia')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar cantidad de viajes por año y mes\n",
    "X_train['pickup_year'] = X_train['pickup_datetime'].dt.year\n",
    "X_train['pickup_month'] = X_train['pickup_datetime'].dt.month\n",
    "# mostrar un grafico de barras con la cantidad de viajes por año y mes\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(data=X_train, x='pickup_year', hue='pickup_month', palette='viridis')\n",
    "plt.title('Cantidad de viajes por año y mes')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Cantidad de viajes')\n",
    "plt.legend(title='Mes', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener el dia de la semana y la hora del dia a partir de pickup_datetime\n",
    "X_train['pickup_day_of_week'] = X_train['pickup_datetime'].dt.dayofweek\n",
    "X_train['pickup_hour'] = X_train['pickup_datetime'].dt.hour\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregar campo franja horaria a partir del campo pickup_hour\n",
    "def franja_horaria(hora):\n",
    "    if 0 <= hora < 6:\n",
    "        return 'Madrugada'\n",
    "    elif 6 <= hora < 12:\n",
    "        return 'Mañana'\n",
    "    elif 12 <= hora < 13:\n",
    "        return 'Mediodia'\n",
    "    elif 13 <= hora < 18:\n",
    "        return 'Tarde'\n",
    "    elif 18 <= hora < 24:\n",
    "        return 'Noche'\n",
    "    else:\n",
    "        return 'Desconocido'\n",
    "X_train['franja_horaria'] = X_train['pickup_hour'].apply(franja_horaria)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar un scatter plot de la distancia en km vs fare_amount, color franja horaria\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=X_train, x='distance_km', y=y_train, hue='franja_horaria', palette='viridis', alpha=0.6)\n",
    "plt.title('Distancia en km vs Fare Amount por Franja Horaria')\n",
    "plt.xlabel('Distancia (km)')\n",
    "plt.ylabel('Fare Amount')\n",
    "plt.legend(title='Franja Horaria', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar un scatter plot de la distancia en km vs fare_amount, color dia de la semana\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=X_train, x='distance_km', y=y_train, hue='pickup_day_of_week', palette='viridis', alpha=0.6)\n",
    "plt.title('Distancia en km vs Fare Amount por pickup_day_of_week')\n",
    "plt.xlabel('Distancia (km)')\n",
    "plt.ylabel('Fare Amount')\n",
    "plt.legend(title='pickup_day_of_week', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
