{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfS9klMysiJe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler   # u otros scalers\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from distancia import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Etu10JAIsiJk"
   },
   "outputs": [],
   "source": [
    "### carga datos de dataset en dataframe\n",
    "file_path= 'uber_fares.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "### visualizacion de algunos datos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xd_uOYe1siJn"
   },
   "source": [
    "#### Contexto  \n",
    "El proyecto trata sobre **Uber Inc.**, la compañía de taxis más grande del mundo. En este trabajo, nuestro objetivo es **predecir la tarifa de futuros viajes**.  \n",
    "\n",
    "Uber brinda servicio a millones de clientes cada día, por lo que gestionar adecuadamente sus datos es clave para desarrollar nuevas estrategias de negocio y obtener mejores resultados.  \n",
    "\n",
    "### Variables del conjunto de datos  \n",
    "\n",
    "**Variables explicativas:**  \n",
    "- **key**: identificador único de cada viaje.  \n",
    "- **pickup_datetime**: fecha y hora en que se inició el viaje.  \n",
    "- **passenger_count**: cantidad de pasajeros en el vehículo (dato ingresado por el conductor).  \n",
    "- **pickup_longitude**: longitud del punto de inicio del viaje.  \n",
    "- **pickup_latitude**: latitud del punto de inicio del viaje.  \n",
    "- **dropoff_longitude**: longitud del punto de destino.  \n",
    "- **dropoff_latitude**: latitud del punto de destino.  \n",
    "\n",
    "**Variable objetivo (target):**  \n",
    "- **fare_amount**: costo del viaje en dólares.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tf2N8kt_siJp",
    "outputId": "8b0f80b4-5783-4e13-cc89-aa7416b0f0f3"
   },
   "outputs": [],
   "source": [
    "### Columnas, ¿cuáles son variables numéricas y cuales variables categóricas?\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este dataset trabajaremos con algunas columnas de interes, las cuales clasificamos a continuacion dependiendo el tipo de variable:\n",
    "\n",
    "*   **fare_amount:**   cuantitativa continua\n",
    "*   **pickup_datetime:** cualitativa nominal\n",
    "*   **pickup_longitude:** cuantitativa continua\n",
    "*   **pickup_latitude:** cuantitativa continua\n",
    "*   **dropoff_longitude:** cuantitativa continua\n",
    "*   **dropoff_latitude:** cuantitativa continua\n",
    "*   **passenger_count:** cuantitativa discreta\n",
    "\n",
    "Lo primero que realizaremos será utilizar el método `.info()` para verificar que el tipo de dato en cada variable es correcto, detectar la presencia de valores nulos y valores atípicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descartar valores del target negativos, cero o nulos\n",
    "# Mostrar la cantidad de registros antes y después de la limpieza\n",
    "print(f\"Cantidad de registros antes de la limpieza: {len(df)}\") \n",
    "df = df[df['fare_amount'] > 0]\n",
    "print(f\"Cantidad de registros después de la limpieza: {len(df)}\")\n",
    "df = df.dropna(subset=['fare_amount'])\n",
    "print(f\"Cantidad de registros después de eliminar nulos: {len(df)}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregar las variables de distancia y tiempo antes de dividir en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambia el tipo de dato object -> datetime\n",
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])                   \n",
    "# Elimina las filas con valores nulos\n",
    "#train_df.dropna(inplace=True)     #No haria falta lo hacemos con imputacion\n",
    "\n",
    "# Eliminación de columnas que no son de interes\n",
    "df = df.drop('key', axis = 1)\n",
    "df = df.drop('date', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar mas caraterísticas a partir de las coordenadas geográficas\n",
    "df[\"delta_lat\"] = df[\"dropoff_latitude\"] - df[\"pickup_latitude\"]\n",
    "df[\"delta_lon\"] = df[\"dropoff_longitude\"] - df[\"pickup_longitude\"]\n",
    "\n",
    "df[\"distance_km\"] = df.apply(\n",
    "    lambda row: haversine(\n",
    "        row[\"pickup_longitude\"], row[\"pickup_latitude\"],\n",
    "        row[\"dropoff_longitude\"], row[\"dropoff_latitude\"]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener el dia de la semana y la hora del dia a partir de pickup_datetime\n",
    "df['pickup_day_of_week'] = df['pickup_datetime'].dt.dayofweek\n",
    "df['pickup_hour'] = df['pickup_datetime'].dt.hour\n",
    "# agregar campo franja horaria a partir del campo pickup_hour\n",
    "def franja_horaria(hora):\n",
    "    if 0 <= hora < 6:\n",
    "        return 'Madrugada'\n",
    "    elif 6 <= hora < 12:\n",
    "        return 'Mañana'\n",
    "    elif 12 <= hora < 13:\n",
    "        return 'Mediodia'\n",
    "    elif 13 <= hora < 18:\n",
    "        return 'Tarde'\n",
    "    elif 18 <= hora < 24:\n",
    "        return 'Noche'\n",
    "    else:\n",
    "        return 'Desconocido'\n",
    "df['franja_horaria'] = df['pickup_hour'].apply(franja_horaria)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir df en train y test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar la fila con valores nulos\n",
    "train_df[train_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de los datos\n",
    "Podemos observar a traves del 'train_df.info' que tenemos 200.000 datos donde las columnas 'dropoff_longitude' y 'dropoff_latitude' poseen un valor faltante en sus datos. Consideramos que al tener una muestra de datos abundante, decidimos eliminarlos del dataset ya que no afecta al entrenamiento del modelo y evitar imputar los datos con un valor promedio. Además, modificamos el tipo de dato de 'pickup_datetime' para verificar que todas las fechas ingresadas hayan sido correctamente cargadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de esto, realizamos un '.describe()' sobre las variables numericas y consideramos los resultados para analizar cada variable del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Análisis de la columna `passenger_count`:**\n",
    "\n",
    "Rango válido de la variable: [0, 6] pasajeros\n",
    "\n",
    "A partir del análisis exploratorio mediante `.describe()`, se detectó que el valor máximo registrado en la variable fue de 208 pasajeros por viaje, lo cual constituye un error en la carga de datos. Para visualizar la distribución se realizaron diferentes gráficos:  \n",
    "\n",
    "- En el **primer boxplot**, se observa claramente el valor atípico de 208, lo que impide una correcta interpretación del resto de los datos.  \n",
    "- Al excluir dicho valor extremo, el **segundo boxplot** permite observar mejor la dispersión real de la variable.  \n",
    "\n",
    "Además, se identificaron registros con 0 pasajeros, los cuales también son inconsistentes, ya que un viaje no puede realizarse sin pasajeros.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x = train_df['passenger_count'])\n",
    "plt.title('Boxplot de cantidad de pasajeros sin filtrar')\n",
    "plt.xlabel('Cantidad de pasajeros')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x = train_df[train_df['passenger_count'] < 208]['passenger_count'])\n",
    "plt.title('Boxplot de cantidad de pasajero < 208')\n",
    "plt.xlabel('Cantidad de pasajeros')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_df[train_df['passenger_count'] < 208]['passenger_count'], color = 'green')\n",
    "plt.title('Histograma de cantidad de pasajeros menor a 208')\n",
    "plt.xlabel('Cantidad de pasajeros')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para solucionar este problema y no eliminar dichos registros, se decidió imputar los valores inválidos con la **mediana de la distribución**. La mediana es la medida de tendencia central y es robusta frente a valores atípicos y representa de forma adecuada la cantidad más común de pasajeros en los viajes (generalmente 1). Finalmente, la columna fue convertida a valores enteros para mantener consistencia en la variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "train_df.loc[train_df['passenger_count'] > 6, 'passenger_count'] = pd.NA\n",
    "imputer = SimpleImputer(strategy='median')                                      # Imputar con la mediana\n",
    "train_df['passenger_count'] = imputer.fit_transform(train_df[['passenger_count']])\n",
    "train_df['passenger_count'] = train_df['passenger_count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_df['passenger_count'], color = 'green')\n",
    "plt.title('Histograma de cantidad de pasajeros transformado')\n",
    "plt.xlabel('Cantidad de pasajeros')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análisis de las columnas `pickup_latitude`, `dropoff_latitude`, `pickup_longitude` y `dropoff_longitude`\n",
    "\n",
    "Para analizar estos datos, lo primero que realizamos fue la visualización gráfica de cada variable. En estas gráficas se observan bastantes valores atípicos que no corresponden a rangos válidos de latitud y longitud:  \n",
    "\n",
    "- **Rangos globales válidos**:  \n",
    "  - Latitud: -90 a 90  \n",
    "  - Longitud: -180 a 180  \n",
    "\n",
    "Vamos a considerar todas las coordenadas que caigan dentro de estos rangos o bien tengan una sola coordenada de las 4 posibles fuera del rango, sea cero o nula.\n",
    "En estos casos imputariamos la coordenada inválida con el algoritmo K-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,5))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"Datos de 'pickup_longitude'\")\n",
    "sns.boxplot(train_df['pickup_longitude'])\n",
    "plt.ylabel('Longitud de inicio')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"Datos de 'dropoff_longitude'\")\n",
    "sns.boxplot(train_df['dropoff_longitude'])\n",
    "plt.ylabel('Longitud final')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"Datos de 'pickup_latitude'\")\n",
    "sns.boxplot(train_df['pickup_latitude'])\n",
    "plt.ylabel('Latitud de inicio')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"Datos de 'dropoff_latitude'\")\n",
    "sns.boxplot(train_df['dropoff_latitude'])\n",
    "plt.ylabel('Latitud final')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que existen registros en los cuales tanto la latitud como la longitud (de inicio y de destino) tienen valor igual a 0. Estos registros no aportan información relevante al análisis, ya que corresponden a errores de carga, por lo que se decidió **eliminarlos del dataset** para trabajar únicamente con datos reales.  \n",
    "\n",
    "Por otro lado, aquellos registros en los que solo **una de las coordenadas** (latitud o longitud, ya sea en inicio o destino) tiene valor igual a 0, pueden ser imputados por aproximación. En este caso, en lugar de eliminarlos, se optó por reemplazar dichos valores utilizando el método de imputación por K-vecinos más cercanos (KNN), lo cual permite estimar las coordenadas faltantes en base a los viajes más similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recorrer el dataset train_df y chequear si las coordenadas son validas o cero o nan y si no los son reemplazarlas con NaN\n",
    "# si una fila tiene mas de 1 coordenada invalida, eliminar la fila\n",
    "# mostrar la cantidad de filas eliminadas\n",
    "# mostrar la cantidad de filas modificadas a NaN\n",
    "\n",
    "modified_count = 0\n",
    "initial_rows = train_df.shape[0] # cantidad inicial de filas\n",
    "for index, row in train_df.iterrows():\n",
    "    invalid_count = 0\n",
    "\n",
    "    if not (-90 <= row['pickup_latitude'] <= 90) or abs(row['pickup_latitude']) < 0.1 or pd.isna(row['pickup_latitude']): \n",
    "        train_df.at[index, 'pickup_latitude'] = pd.NA\n",
    "        invalid_count += 1\n",
    "    if not (-90 <= row['dropoff_latitude'] <= 90 or row['dropoff_latitude'] == 0.0) or pd.isna(row['dropoff_latitude']):\n",
    "        train_df.at[index, 'dropoff_latitude'] = pd.NA\n",
    "        invalid_count += 1\n",
    "    if not (-180 <= row['pickup_longitude'] <= 180) or row['pickup_longitude'] == 0.0 or pd.isna(row['pickup_longitude']):\n",
    "        train_df.at[index, 'pickup_longitude'] = pd.NA\n",
    "        invalid_count += 1\n",
    "    if not (-180 <= row['dropoff_longitude'] <= 180) or row['dropoff_longitude'] == 0.0 or pd.isna(row['dropoff_longitude']):\n",
    "        train_df.at[index, 'dropoff_longitude'] = pd.NA\n",
    "        invalid_count += 1\n",
    "    if invalid_count > 1:\n",
    "        train_df = train_df.drop(index)\n",
    "    elif invalid_count == 1:\n",
    "        modified_count += 1\n",
    "        # marcar la fila como modificada columna imputada = True\n",
    "        train_df.at[index, 'imputar'] = True\n",
    "\n",
    "print(f'Cantidad de filas modificadas a NaN: {modified_count}')\n",
    "final_rows = train_df.shape[0] # cantidad final de filas\n",
    "print(f'Cantidad de filas eliminadas: {initial_rows - final_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar las filas imputadas \n",
    "train_df[train_df['imputar'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "columnas = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
    "#k muy pequeño → más sensible a ruido. k muy grande → valores muy suavizados, se pierde variabilidad real.\n",
    "\n",
    "# Crear imputador KNN\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "train_df[columnas] = knn_imputer.fit_transform(train_df[columnas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mostrar las filas imputadas \n",
    "train_df[train_df['imputar'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# falta recalcular la distancia de los registros a imputar, ya que se modificaron las coordenadas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,5))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"Datos de 'pickup_longitude'\")\n",
    "sns.boxplot(train_df['pickup_longitude'], color=\"skyblue\")\n",
    "plt.ylabel('Longitud de inicio')\n",
    "plt.ylim(-100, 50)\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"Datos de 'dropoff_longitude'\")\n",
    "sns.boxplot(train_df['dropoff_longitude'], color=\"pink\")\n",
    "plt.ylabel('Longitud final')\n",
    "plt.ylim(-100, 50)\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"Datos de 'pickup_latitude'\")\n",
    "sns.boxplot(train_df['pickup_latitude'], color=\"skyblue\")\n",
    "plt.ylabel('Latitud de inicio')\n",
    "plt.ylim(-100, 60)\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"Datos de 'dropoff_latitude'\")\n",
    "sns.boxplot(train_df['dropoff_latitude'], color=\"pink\")\n",
    "plt.ylabel('Latitud final')\n",
    "plt.ylim(-100, 60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograma de la distancia en km\n",
    "\n",
    "plt.hist(train_df['distance_km'], bins=50, color='blue', alpha=0.7)\n",
    "plt.title('Histograma de la distancia en km')\n",
    "plt.xlabel('Distancia (km)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograma del logaritmo de la distancia en km\n",
    "plt.hist(np.log1p(train_df['distance_km']), bins=50, color='blue', alpha=0.7)\n",
    "plt.title('Histograma del logaritmo de la distancia en km')\n",
    "plt.xlabel('Log(Distancia + 1)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['distance_km'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular el primer cuartil (Q1) y el tercer cuartil (Q3)\n",
    "Q1 = train_df['distance_km'].quantile(0.25).round(2)\n",
    "Q3 = train_df['distance_km'].quantile(0.75).round(2)\n",
    "IQR = Q3 - Q1\n",
    "# definir los límites para los valores atípicos\n",
    "lower_bound = (Q1 - 5 * IQR).round(2)\n",
    "upper_bound = (Q3 + 5 * IQR).round(2)\n",
    "print(f'Q1: {Q1}, Q3: {Q3}, IQR: {IQR}, Lower Bound: {lower_bound}, Upper Bound: {upper_bound}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular la cantidad de valores atípicos\n",
    "outliers = train_df[(train_df['distance_km'] < lower_bound) | (train_df['distance_km'] > upper_bound)]\n",
    "print(f'Cantidad de valores atípicos: {outliers.shape[0]}')\n",
    "print(f'Porcentaje de valores atípicos: {outliers.shape[0] / train_df.shape[0] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener index de los datos para eliminar los valores atípicos\n",
    "outlier_indices = outliers.index\n",
    "# eliminar los datos atípicos de train_df \n",
    "train_df = train_df.drop(outlier_indices)\n",
    "\n",
    "\n",
    "plt.hist(train_df['distance_km'], bins=50, color='blue', alpha=0.7)\n",
    "plt.title('Histograma de la distancia en km')\n",
    "plt.xlabel('Distancia (km)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar cantidad de viajes por año y mes\n",
    "train_df['pickup_year'] = train_df['pickup_datetime'].dt.year\n",
    "train_df['pickup_month'] = train_df['pickup_datetime'].dt.month\n",
    "# mostrar un grafico de barras con la cantidad de viajes por año y mes\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(data=train_df, x='pickup_year', hue='pickup_month', palette='viridis')\n",
    "plt.title('Cantidad de viajes por año y mes')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Cantidad de viajes')\n",
    "plt.legend(title='Mes', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar un scatter plot de la distancia en km vs fare_amount, color franja horaria\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=train_df, x='distance_km', y='fare_amount', hue='franja_horaria', palette='viridis', alpha=0.6)\n",
    "plt.title('Distancia en km vs Fare Amount por Franja Horaria')\n",
    "plt.xlabel('Distancia (km)')\n",
    "plt.ylabel('Fare Amount')\n",
    "plt.legend(title='Franja Horaria', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tarifas muy altas con poca distancia, habria que revisar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograma del fare_amount\n",
    "plt.hist(train_df['fare_amount'], bins=50, color='orange', alpha=0.7)\n",
    "plt.title('Histograma del fare_amount')\n",
    "plt.xlabel('Fare Amount')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['fare_amount'] > 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar un scatter plot de la distancia en km vs fare_amount, color dia de la semana\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=train_df, x='distance_km', y='fare_amount', hue='pickup_day_of_week', palette='viridis', alpha=0.6)\n",
    "plt.title('Distancia en km vs Fare Amount por pickup_day_of_week')\n",
    "plt.xlabel('Distancia (km)')\n",
    "plt.ylabel('Fare Amount')\n",
    "plt.legend(title='pickup_day_of_week', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quedaria revisar esas tarifas muy altas con poca distancia ver si las quitamos\n",
    "# separar train_df en X e y\n",
    "# aplicar escalado a las variables numericas y codificacion one hot a las categoricas\n",
    "# definir una metrica para comparar modelos: RMSE, MAE, R2\n",
    "# aplicar el algoritmo de regresion lineal y evaluar el modelo: descenso del gradiente minibatch"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
